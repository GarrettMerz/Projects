{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "import random\n",
    "\n",
    "#allow GPU memory growth because TF 2.1 and CUDNN aren't getting along right now!\n",
    "#config = tf.compat.v1.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "with open('/home/garrett/KagglesData/Butterflies/fgvc_fg_training.json','r') as anno_train:\n",
    "    train = json.load(anno_train)\n",
    "with open('/home/garrett/KagglesData/Butterflies/fgvc_fg_testing.json','r') as anno_test:\n",
    "    test = json.load(anno_test)\n",
    "\n",
    "#print(train)   \n",
    "\n",
    "\n",
    "train.keys()\n",
    "test.keys()\n",
    "test_df = pd.DataFrame()\n",
    "test_df = test_df.append(test['images'], ignore_index=True)\n",
    "train_df = pd.DataFrame()\n",
    "train_df = train_df.append(train['images'], ignore_index=True)\n",
    "train_df_anno = pd.DataFrame()\n",
    "train_df_anno = train_df_anno.append(train['annotations'], ignore_index=True)\n",
    "train_df['category_id'] = train_df_anno['category_id']\n",
    "test_df = test_df.append(test['images'], ignore_index=True)\n",
    "test_df_anno = pd.DataFrame()\n",
    "\n",
    "train_df.head()\n",
    "foldertrain = '/home/garrett/KagglesData/Butterflies/data-images/training/images/'\n",
    "foldertest = '/home/garrett/KagglesData/Butterflies/data-images/testing/images/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#the images are all different sizes, so we will need to resize them. Size up to 600x600\n",
    "\n",
    "#Takes dataframe and image directory, returns 600x600x3x(SIZE) ndarray of images.\n",
    "#This is very slow, so to avoid looping over the dataframe more times than necessary we combine the function\n",
    "# to get labels and the function to creat padded images into one.\n",
    "\n",
    "def getLabelsAndPaddedImages(df, folder, isTrain):\n",
    "    #slicesize = len(df.index)\n",
    "    slicesize = 1000\n",
    "    cat_labels = []\n",
    "    images = []\n",
    "    for i in range(slicesize):\n",
    "        # define subplot\n",
    "        # define filename\n",
    "        filename = folder + df.at[i, 'file_name']\n",
    "        # load image pixels. Images are rgb\n",
    "        image = imread(filename)\n",
    "        imresize = cv2.resize(image, (600,600),interpolation = cv2.INTER_AREA)\n",
    "        #plot raw rgb pixel data\n",
    "        #if i < 9:\n",
    "        #    pyplot.subplot(330 + 1 + i)\n",
    "        #    pyplot.imshow(imresize)\n",
    "        # show the figure\n",
    "        #pyplot.show()\n",
    "        images.append(imresize)\n",
    "        if(i%100 == 0):\n",
    "            print(\"got image \"),\n",
    "            print(i)\n",
    "        if isTrain == 1:\n",
    "            labels = np.zeros(5419)\n",
    "            cat_label = df.at[i,'category_id']\n",
    "            labels[cat_label] = 1\n",
    "            cat_labels.append(labels)\n",
    "    if (isTrain == 1):\n",
    "            return (cat_labels, images)\n",
    "    else: return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got image \n",
      "0\n",
      "got image \n",
      "100\n",
      "got image \n",
      "200\n",
      "got image \n",
      "300\n",
      "got image \n",
      "400\n",
      "got image \n",
      "500\n",
      "got image \n",
      "600\n",
      "got image \n",
      "700\n",
      "got image \n",
      "800\n",
      "got image \n",
      "900\n",
      "got image \n",
      "0\n",
      "got image \n",
      "100\n",
      "got image \n",
      "200\n",
      "got image \n",
      "300\n",
      "got image \n",
      "400\n",
      "got image \n",
      "500\n",
      "got image \n",
      "600\n",
      "got image \n",
      "700\n",
      "got image \n",
      "800\n",
      "got image \n",
      "900\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_labels_tot,train_img_tot = getLabelsAndPaddedImages(train_df, foldertrain, 1)\n",
    "test_img = getLabelsAndPaddedImages(test_df, foldertest,0)\n",
    "\n",
    "c = list(zip(train_labels_tot, train_img_tot))\n",
    "random.shuffle(c)\n",
    "train_labels_tot_shuf, train_img_tot_shuf = zip(*c)\n",
    "\n",
    "train_labels = np.array(train_labels_tot_shuf[:int(len(train_labels_tot_shuf)/2)])\n",
    "validation_labels = np.array(train_labels_tot_shuf[int(len(train_labels_tot_shuf)/2):])\n",
    "train_img = np.array(train_img_tot_shuf[:int(len(train_img_tot_shuf)/2)])\n",
    "validation_img = np.array(train_img_tot_shuf[int(len(train_img_tot_shuf)/2):])\n",
    "\n",
    "print(len(train_img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we build the basic Convnet. Use Tensorflow + Keras for this on my RTX gpu.\n",
    "#Let's try to make ResNet from scratch.\n",
    "#First, define the inception modules.\n",
    "\n",
    "\n",
    "# Define a sequential model\n",
    "input_shape = (600,600,3)\n",
    "num_classes= 5419\n",
    "model = Sequential()\n",
    "# add first convolutional layer\n",
    "model.add(Conv2D(32, kernel_size=(7, 7), activation='elu', input_shape=input_shape))\n",
    "# add second convolutional layer\n",
    "model.add(Conv2D(32, (5, 5), activation='elu'))\n",
    "# add one max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# add one dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "# add flatten layer\n",
    "model.add(Flatten())\n",
    "# add dense layer\n",
    "model.add(Dense(16, activation='relu'))\n",
    "# add another dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# add dense layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# complile the model and view its architecture\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,  optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 1\n",
    "history = model.fit(train_img,train_labels, batch_size=batch_size,epochs = epochs, validation_data = (validation_img,validation_labels))\n",
    "\n",
    "print('\\n# Generate predictions for test set')\n",
    "predictions = model.predict(np.array(test_img))\n",
    "print('predictions shape:', predictions.shape)\n",
    "predvals = tf.math.argmax(predictions, axis = 1)\n",
    "print(predvals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
