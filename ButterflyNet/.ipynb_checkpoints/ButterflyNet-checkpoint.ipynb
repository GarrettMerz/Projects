{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 294583569467726928\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4327342080\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7198020625127202664\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n",
      "                              file_name category_id\n",
      "0  0000031e2e9701e24d046c0dc3889bde.jpg         578\n",
      "1  00001246ce7f88ec292384abcc58d3e0.jpg         438\n",
      "2  00006fd6c3cd2e525e2df491e157844d.jpg        3990\n",
      "3  0000a8ef4598a73544df0d42ca754a73.jpg        2964\n",
      "4  0000d2de78907e422f61ec502819e27b.jpg        1757\n",
      "Found 355079 validated image filenames belonging to 5419 classes.\n",
      "Found 118359 validated image filenames belonging to 5419 classes.\n",
      "Found 118282 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "#from tensorflow.keras.utils import plot_model\n",
    "#from resnets_utils import *\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "with open('/home/garrett/KagglesData/Butterflies/fgvc_fg_training.json','r') as anno_train:\n",
    "    train = json.load(anno_train)\n",
    "with open('/home/garrett/KagglesData/Butterflies/fgvc_fg_testing.json','r') as anno_test:\n",
    "    test = json.load(anno_test)\n",
    "\n",
    "#print(train)   \n",
    "\n",
    "\n",
    "train.keys()\n",
    "test.keys()\n",
    "test_df = pd.DataFrame()\n",
    "test_df = test_df.append(test['images'], ignore_index=True)\n",
    "train_df = pd.DataFrame()\n",
    "train_df = train_df.append(train['images'], ignore_index=True)\n",
    "train_df_anno = pd.DataFrame()\n",
    "train_df_anno = train_df_anno.append(train['annotations'], ignore_index=True)\n",
    "train_df['category_id'] = train_df_anno['category_id'].astype('str')\n",
    "test_df = test_df.append(test['images'], ignore_index=True)\n",
    "test_df_anno = pd.DataFrame()\n",
    "\n",
    "train_df = train_df.drop(['id', 'width', 'height', 'url', 'license'], axis = 1)\n",
    "test_df = test_df.drop(['id', 'width', 'height', 'url', 'license'], axis = 1)\n",
    "\n",
    "print(train_df.head())\n",
    "\n",
    "\n",
    "foldertrain = '/home/garrett/KagglesData/Butterflies/data-images/training/images/'\n",
    "foldertest = '/home/garrett/KagglesData/Butterflies/data-images/testing/images/'\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=foldertrain,\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"category_id\",\n",
    "    subset=\"training\",\n",
    "    batch_size=10,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    classes = [str(x) for x in range(5419)],\n",
    "    target_size=(600,600))\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=foldertrain,\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"category_id\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=10,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    classes = [str(x) for x in range(5419)],    \n",
    "    target_size=(600,600))\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=test_df,\n",
    "directory=foldertest,\n",
    "x_col=\"file_name\",\n",
    "y_col=None,\n",
    "batch_size=10,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(600,600))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#the images are all different sizes, so we will need to resize them. Size up to 600x600\n",
    "\n",
    "#Takes dataframe and image directory, returns 600x600x3x(SIZE) ndarray of images.\n",
    "#This is very slow, so to avoid looping over the dataframe more times than necessary we combine the function\n",
    "# to get labels and the function to creat padded images into one.\n",
    "\n",
    "def getLabelsAndPaddedImages(df, folder, isTrain):\n",
    "    #start with only a small dataset, to make sure the network architecture is ok\n",
    "    slicesize = len(df.index)\n",
    "    #slicesize = 1000\n",
    "    cat_labels = []\n",
    "    images = []\n",
    "    for i in range(slicesize):\n",
    "        # define subplot\n",
    "        # define filename\n",
    "        filename = folder + df.at[i, 'file_name']\n",
    "        # load image pixels. Images are rgb\n",
    "        image = imread(filename)\n",
    "        imresize = cv2.resize(image, (600,600),interpolation = cv2.INTER_AREA)\n",
    "        #plot raw rgb pixel data\n",
    "        #if i < 9:\n",
    "        #    pyplot.subplot(330 + 1 + i)\n",
    "        #    pyplot.imshow(imresize)\n",
    "        # show the figure\n",
    "        #pyplot.show()\n",
    "        images.append(imresize)\n",
    "        if(i%100 == 0):\n",
    "            print(\"got image \"),\n",
    "            print(i)\n",
    "        if isTrain == 1:\n",
    "            labels = np.zeros(5419)\n",
    "            cat_label = df.at[i,'category_id']\n",
    "            labels[cat_label] = 1\n",
    "            cat_labels.append(labels)\n",
    "    if (isTrain == 1):\n",
    "            #print(cat_labels)\n",
    "            return (cat_labels, images)\n",
    "    else: return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_labels_tot,train_img_tot = getLabelsAndPaddedImages(train_df, foldertrain, 1)\\ntest_img = getLabelsAndPaddedImages(test_df, foldertest,0)\\n\\n#Normalize and standardize images!!!\\n\\n\\n\\n\\nc = list(zip(train_labels_tot, train_img_tot))\\nnp.random.shuffle(c)\\ntrain_labels_tot_shuf, train_img_tot_shuf = zip(*c)\\n\\ntrain_labels = np.array(train_labels_tot_shuf[:int(9*len(train_labels_tot_shuf)/10)])\\nvalidation_labels = np.array(train_labels_tot_shuf[int(len(train_labels_tot_shuf)/10):])\\ntrain_img = np.array(train_img_tot_shuf[:int(9*len(train_labels_tot_shuf)/10)])\\nvalidation_img = np.array(train_img_tot_shuf[int(len(train_img_tot_shuf)/10):])\\n\\nprint(len(train_img))\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_labels_tot,train_img_tot = getLabelsAndPaddedImages(train_df, foldertrain, 1)\n",
    "test_img = getLabelsAndPaddedImages(test_df, foldertest,0)\n",
    "\n",
    "#Normalize and standardize images!!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "c = list(zip(train_labels_tot, train_img_tot))\n",
    "np.random.shuffle(c)\n",
    "train_labels_tot_shuf, train_img_tot_shuf = zip(*c)\n",
    "\n",
    "train_labels = np.array(train_labels_tot_shuf[:int(9*len(train_labels_tot_shuf)/10)])\n",
    "validation_labels = np.array(train_labels_tot_shuf[int(len(train_labels_tot_shuf)/10):])\n",
    "train_img = np.array(train_img_tot_shuf[:int(9*len(train_labels_tot_shuf)/10)])\n",
    "validation_img = np.array(train_img_tot_shuf[int(len(train_img_tot_shuf)/10):])\n",
    "\n",
    "print(len(train_img))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-40f696ff7d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_labels' is not defined"
     ]
    }
   ],
   "source": [
    "#print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we build the basic Convnet. Use Tensorflow + Keras for this on my RTX gpu.\n",
    "#Let's make ResNet from scratch in Keras. First, define the basic residual module.\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \n",
    "    # defining name basis\n",
    "    cNN_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_forlater = X\n",
    "    \n",
    "    # First CNN, batchnorm, and RELU. Use Glorot uniform init for the CNN layers and ELU activation.\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = cNN_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('elu')(X)\n",
    "\n",
    "    # Second CNN, batchnorm, and RELU.\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = cNN_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('elu')(X)\n",
    "\n",
    "    # Third CNN and batchnorm\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = cNN_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add original X value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_forlater])\n",
    "    X = Activation('elu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_forlater = X\n",
    "\n",
    "    # First CNN, batchnorm, and RELU. Use Glorot uniform init for the CNN layers and ELU activation.\n",
    "\n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('elu')(X)\n",
    "\n",
    "    # Second CNN, batchnorm, and RELU. Use Glorot uniform init for the CNN layers and ELU activation.\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('elu')(X)\n",
    "\n",
    "\n",
    "    # Third CNN, batchnorm, and RELU. Use Glorot uniform init for the CNN layers and ELU activation.\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "\n",
    "    X_forlater = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n",
    "                        kernel_initializer = glorot_uniform(seed=0))(X_forlater)\n",
    "    X_forlater = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_forlater)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_forlater])\n",
    "    X = Activation('elu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet(input_shape=(600, 600, 3), classes=5419):\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('elu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[4, 4, 16], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [4, 4, 16], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [4, 4, 16], stage=2, block='c')\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [8, 8, 32], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [8, 8, 32], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [8, 8, 32], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [8, 8, 32], stage=3, block='d')\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [16, 16, 64], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [16, 16, 64], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [16, 16, 64], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [16, 16, 64], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [16, 16, 64], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [16, 16, 64], stage=4, block='f')\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [32,32,128], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [32, 32, 128], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [32, 32, 128], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= ResNet(input_shape=(600, 600, 3))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/garrett/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  195/35507 [..............................] - ETA: 1:58:42 - loss: 10.4673 - accuracy: 0.0051"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# Generate predictions for test set')\n",
    "predictions = model.predict(np.array(test_img))\n",
    "print('predictions shape:', predictions.shape)\n",
    "predvals = tf.math.argmax(predictions, axis = 1)\n",
    "print(predvals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
