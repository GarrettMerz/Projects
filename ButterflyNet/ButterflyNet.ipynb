{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7011650025613100105\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3964141568\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10889746553803972141\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "#from tensorflow.keras.utils import plot_model\n",
    "#from resnets_utils import *\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "#allow GPU memory growth because TF 2.1 and CUDNN aren't getting along right now!\n",
    "#config = tf.compat.v1.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "with open('/home/garrett/KagglesData/Butterflies/fgvc_fg_training.json','r') as anno_train:\n",
    "    train = json.load(anno_train)\n",
    "with open('/home/garrett/KagglesData/Butterflies/fgvc_fg_testing.json','r') as anno_test:\n",
    "    test = json.load(anno_test)\n",
    "\n",
    "#print(train)   \n",
    "\n",
    "\n",
    "train.keys()\n",
    "test.keys()\n",
    "test_df = pd.DataFrame()\n",
    "test_df = test_df.append(test['images'], ignore_index=True)\n",
    "train_df = pd.DataFrame()\n",
    "train_df = train_df.append(train['images'], ignore_index=True)\n",
    "train_df_anno = pd.DataFrame()\n",
    "train_df_anno = train_df_anno.append(train['annotations'], ignore_index=True)\n",
    "train_df['category_id'] = train_df_anno['category_id']\n",
    "test_df = test_df.append(test['images'], ignore_index=True)\n",
    "test_df_anno = pd.DataFrame()\n",
    "\n",
    "train_df.head()\n",
    "foldertrain = '/home/garrett/KagglesData/Butterflies/data-images/training/images/'\n",
    "foldertest = '/home/garrett/KagglesData/Butterflies/data-images/testing/images/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#the images are all different sizes, so we will need to resize them. Size up to 600x600\n",
    "\n",
    "#Takes dataframe and image directory, returns 600x600x3x(SIZE) ndarray of images.\n",
    "#This is very slow, so to avoid looping over the dataframe more times than necessary we combine the function\n",
    "# to get labels and the function to creat padded images into one.\n",
    "\n",
    "def getLabelsAndPaddedImages(df, folder, isTrain):\n",
    "    #slicesize = len(df.index)\n",
    "    slicesize = 1000\n",
    "    cat_labels = []\n",
    "    images = []\n",
    "    for i in range(slicesize):\n",
    "        # define subplot\n",
    "        # define filename\n",
    "        filename = folder + df.at[i, 'file_name']\n",
    "        # load image pixels. Images are rgb\n",
    "        image = imread(filename)\n",
    "        imresize = cv2.resize(image, (600,600),interpolation = cv2.INTER_AREA)\n",
    "        #plot raw rgb pixel data\n",
    "        #if i < 9:\n",
    "        #    pyplot.subplot(330 + 1 + i)\n",
    "        #    pyplot.imshow(imresize)\n",
    "        # show the figure\n",
    "        #pyplot.show()\n",
    "        images.append(imresize)\n",
    "        if(i%100 == 0):\n",
    "            print(\"got image \"),\n",
    "            print(i)\n",
    "        if isTrain == 1:\n",
    "            labels = np.zeros(5419)\n",
    "            cat_label = df.at[i,'category_id']\n",
    "            labels[cat_label] = 1\n",
    "            cat_labels.append(labels)\n",
    "    if (isTrain == 1):\n",
    "            #print(cat_labels)\n",
    "            return (cat_labels, images)\n",
    "    else: return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got image \n",
      "0\n",
      "got image \n",
      "100\n",
      "got image \n",
      "200\n",
      "got image \n",
      "300\n",
      "got image \n",
      "400\n",
      "got image \n",
      "500\n",
      "got image \n",
      "600\n",
      "got image \n",
      "700\n",
      "got image \n",
      "800\n",
      "got image \n",
      "900\n",
      "got image \n",
      "0\n",
      "got image \n",
      "100\n",
      "got image \n",
      "200\n",
      "got image \n",
      "300\n",
      "got image \n",
      "400\n",
      "got image \n",
      "500\n",
      "got image \n",
      "600\n",
      "got image \n",
      "700\n",
      "got image \n",
      "800\n",
      "got image \n",
      "900\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_labels_tot,train_img_tot = getLabelsAndPaddedImages(train_df, foldertrain, 1)\n",
    "test_img = getLabelsAndPaddedImages(test_df, foldertest,0)\n",
    "\n",
    "c = list(zip(train_labels_tot, train_img_tot))\n",
    "np.random.shuffle(c)\n",
    "train_labels_tot_shuf, train_img_tot_shuf = zip(*c)\n",
    "\n",
    "train_labels = np.array(train_labels_tot_shuf[:int(len(train_labels_tot_shuf)/2)])\n",
    "validation_labels = np.array(train_labels_tot_shuf[int(len(train_labels_tot_shuf)/2):])\n",
    "train_img = np.array(train_img_tot_shuf[:int(len(train_img_tot_shuf)/2)])\n",
    "validation_img = np.array(train_img_tot_shuf[int(len(train_img_tot_shuf)/2):])\n",
    "\n",
    "print(len(train_img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we build the basic Convnet. Use Tensorflow + Keras for this on my RTX gpu.\n",
    "#Let's make ResNet from scratch in Keras. First, define the basic residual module.\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \n",
    "    # defining name basis\n",
    "    cNN_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_forlater = X\n",
    "    \n",
    "    # First CNN, batchnorm, and RELU. Use Glorot uniform init for the CNN layers and ELU activation.\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = cNN_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('elu')(X)\n",
    "\n",
    "    # Second CNN, batchnorm, and RELU.\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = cNN_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('elu')(X)\n",
    "\n",
    "    # Third CNN and batchnorm\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = cNN_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add original X value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_forlater])\n",
    "    X = Activation('elu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_forlater = X\n",
    "\n",
    "    # First CNN, batchnorm, and RELU. Use Glorot uniform init for the CNN layers and ELU activation.\n",
    "\n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('elu')(X)\n",
    "\n",
    "    # Second CNN, batchnorm, and RELU. Use Glorot uniform init for the CNN layers and ELU activation.\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('elu')(X)\n",
    "\n",
    "\n",
    "    # Third CNN, batchnorm, and RELU. Use Glorot uniform init for the CNN layers and ELU activation.\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "\n",
    "    X_forlater = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n",
    "                        kernel_initializer = glorot_uniform(seed=0))(X_forlater)\n",
    "    X_forlater = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_forlater)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_forlater])\n",
    "    X = Activation('elu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(600, 600, 3), classes=6):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('elu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs = 25, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 1\n",
    "history = model.fit(train_img,train_labels, batch_size=batch_size,epochs = epochs, validation_data = (validation_img,validation_labels))\n",
    "\n",
    "print('\\n# Generate predictions for test set')\n",
    "predictions = model.predict(np.array(test_img))\n",
    "print('predictions shape:', predictions.shape)\n",
    "predvals = tf.math.argmax(predictions, axis = 1)\n",
    "print(predvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define a sequential model\n",
    "input_shape = (600,600,3)\n",
    "num_classes= 5419\n",
    "model = Sequential()\n",
    "# add first convolutional layer\n",
    "model.add(Conv2D(32, kernel_size=(7, 7), activation='elu', input_shape=input_shape))\n",
    "# add second convolutional layer\n",
    "model.add(Conv2D(32, (5, 5), activation='elu'))\n",
    "# add one max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# add one dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "# add flatten layer\n",
    "model.add(Flatten())\n",
    "# add dense layer\n",
    "model.add(Dense(16, activation='relu'))\n",
    "# add another dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# add dense layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# complile the model and view its architecture\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,  optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
