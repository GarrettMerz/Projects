{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this series of notebooks, I will attempt to do some introductory exploration of various roller derby statistics. We will use the publicly available stats on the FlatTrackStats website. First, I will build a table scraper tool using the BeautifulSoup4 package to parse the stats tables on the website. If not already installed, you will need pandas and BeautifulSoup4 in order to run this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import requests\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from bs4 import BeautifulSoup\n",
    "    from itertools import product\n",
    "    from urllib.request import urlopen\n",
    "    import re\n",
    "    \n",
    "    #First, define a class to parse HTML tables for bouts and players\n",
    "    \n",
    "    class HTMLTableParser:\n",
    "        def parse_url(self, url):\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'lxml')\n",
    "            return [(self.read_table(table)) for table in soup.find_all('table')]      \n",
    "        \n",
    "        def read_table(self, table_tag):\n",
    "            rowspans = []  # track pending rowspans\n",
    "            rows = table_tag.find_all('tr')\n",
    "\n",
    "            # first scan, see how many columns we need\n",
    "            colcount = 0\n",
    "            column_names=[]\n",
    "            for r, row in enumerate(rows):\n",
    "                cells = row.find_all(['td', 'th'], recursive=False)\n",
    "                colcount = max(\n",
    "                    colcount,\n",
    "                    sum(int(c.get('colspan', 1)) or 1 for c in cells[:-1]) + len(cells[-1:]) + len(rowspans))\n",
    "                # update rowspan bookkeeping; 0 is a span to the bottom. \n",
    "                rowspans += [int(c.get('rowspan', 1)) or len(rows) - r for c in cells]\n",
    "                rowspans = [s - 1 for s in rowspans if s > 1]\n",
    "\n",
    "            # it doesn't matter if there are still rowspan numbers 'active'; no extra\n",
    "            # rows to show in the table means the larger than 1 rowspan numbers in the\n",
    "            # last table row are ignored.    \n",
    "            # build an empty matrix for all possible cells\n",
    "            table = [[None] * colcount for row in rows]\n",
    "\n",
    "\n",
    "            # fill matrix from row data\n",
    "            rowspans = {}  # track pending rowspans, column number mapping to count\n",
    "            for row, row_elem in enumerate(rows):\n",
    "                span_offset = 0  # how many columns are skipped due to row and colspans \n",
    "                for col, cell in enumerate(row_elem.find_all(['td', 'th'], recursive=False)):\n",
    "                    # adjust for preceding row and colspans\n",
    "                    col += span_offset\n",
    "                    while rowspans.get(col, 0):\n",
    "                        span_offset += 1\n",
    "                        col += 1\n",
    "\n",
    "                    # fill table data\n",
    "                    rowspan = rowspans[col] = int(cell.get('rowspan', 1)) or len(rows) - row\n",
    "                    colspan = int(cell.get('colspan', 1)) or colcount - col\n",
    "                    # next column is offset by the colspan\n",
    "                    span_offset += colspan - 1\n",
    "                    value = cell.get_text()\n",
    "                    points = len(cell.find_all(\"div\", {\"class\": \" point\"}))\n",
    "                    pens = cell.find_all(\"div\", {\"class\": \"penalty major\"})  \n",
    "                    if (value == '' or value == '&nbsp') and points != '':\n",
    "                        value = str(points)\n",
    "                    if len(pens) > 0:\n",
    "                        value = ''\n",
    "                        for pen in pens:\n",
    "                            value += pen.find_all(text=True, recursive=False)[0] + \" \"\n",
    "                    if len(cell.find_all(\"div\", {\"class\": \"lead\"}))== 1:\n",
    "                        if value == \"0\": value = \"\"\n",
    "                        value += \"Lead \"\n",
    "                    if len(cell.find_all(\"div\", {\"class\": \"leadloss\"}))== 1:\n",
    "                        if value == \"0\": value = \"\"\n",
    "                        value += \"LeadLoss \"\n",
    "                    if len(cell.find_all(\"div\", {\"class\": \"lost\"}))== 1:\n",
    "                        if value == \"0\": value = \"\"\n",
    "                        value += \"LeadLoss \"                   \n",
    "                    if len(cell.find_all(\"div\", {\"class\": \"call\"}))== 1:\n",
    "                        if value == \"0\": value = \"\"\n",
    "                        value += \"call \"\n",
    "                    if len(cell.find_all(\"div\", {\"class\": \"nopass\"}))== 1:\n",
    "                        if value == \"0\": value = \"\"\n",
    "                        value += \"np \"    \n",
    "                    if len(cell.find_all(\"div\", {\"class\": \"starpass\"}))== 1:\n",
    "                        if value == \"0\": value = \"\"\n",
    "                        value += \"sp \"    \n",
    "                    for drow, dcol in product(range(rowspan), range(colspan)):\n",
    "                        try:\n",
    "                            table[row + drow][col + dcol] = value\n",
    "                            rowspans[col + dcol] = rowspan\n",
    "                        except IndexError:\n",
    "                            # rowspan or colspan outside the confines of the table\n",
    "                            pass\n",
    "\n",
    "                # update rowspan bookkeeping\n",
    "                rowspans = {c: s - 1 for c, s in rowspans.items() if s > 1}\n",
    "            npt = np.array(table)\n",
    "            #df = pd.DataFrame(np.array(table), column_names) \n",
    "            return table\n",
    "\n",
    "        def parse_url_todf(self, url):\n",
    "            tables = self.parse_url(url)\n",
    "            dfs = []\n",
    "            if \"combos\" in url:\n",
    "                for table in tables:\n",
    "                    headers = table.pop(0)\n",
    "                    df = pd.DataFrame(np.array(table), columns=np.array(headers))    \n",
    "                    dfs.append(df)\n",
    "            if \"teams\" in url:\n",
    "                for table in tables:\n",
    "                    headers = table.pop(0)\n",
    "                    df = pd.DataFrame(np.array(table), columns=np.array(headers))    \n",
    "                    dfs.append(df)\n",
    "            if \"jams\" in url:\n",
    "                for table in tables:\n",
    "                    headers = table.pop(0)\n",
    "                    df = pd.DataFrame(np.array(table), columns=np.array(headers))    \n",
    "                    dfs.append(df)        \n",
    "            else:\n",
    "                headers = tables[0]\n",
    "                headersnew = []\n",
    "                for header in headers:\n",
    "                    headernew = [i for i in header if i] \n",
    "                    headersnew.append(headernew)\n",
    "                for i in range(len(tables)-1):\n",
    "                    df = pd.DataFrame(np.array(tables[i+1]), columns=headersnew[i])    \n",
    "                    dfs.append(df)\n",
    "                \n",
    "            return dfs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllBouts(teamID):\n",
    "    npages = 0\n",
    "    links=[]\n",
    "    \n",
    "    base_url = \"http://flattrackstats.com/teams/\"+teamID+\"/bouts\"\n",
    "    text = urlopen(base_url).read()\n",
    "    base_soup = BeautifulSoup(text)\n",
    "    \n",
    "    for listitem in base_soup.findAll('li', class_=\"pager-last last\"):\n",
    "        npages = int(listitem.findAll('a')[0]['href'][-1])\n",
    "    \n",
    "    \n",
    "    for page in range(0,npages):\n",
    "        url = \"http://flattrackstats.com/teams/3393/bouts?page=\"+str(page)\n",
    "        text = urlopen(url).read()\n",
    "        soup = BeautifulSoup(text)\n",
    "        for link in soup.findAll('a', class_=\"boutlink has-stats\"):\n",
    "            if \"node\" not in link['href']:\n",
    "                linkname = link['href']\n",
    "                linksize = len(linkname)\n",
    "                linkstub = linkname[:linksize-8]\n",
    "                links.append(linkstub)\n",
    "         \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/bouts/89967/',\n",
       " '/bouts/89829/',\n",
       " '/bouts/89827/',\n",
       " '/bouts/89825/',\n",
       " '/bouts/88760/',\n",
       " '/bouts/89826/',\n",
       " '/bouts/89082/',\n",
       " '/bouts/89828/',\n",
       " '/bouts/89490/',\n",
       " '/bouts/89485/',\n",
       " '/bouts/89481/',\n",
       " '/bouts/89822/',\n",
       " '/bouts/76966/',\n",
       " '/bouts/74386/',\n",
       " '/bouts/76965/',\n",
       " '/bouts/76964/',\n",
       " '/bouts/74481/',\n",
       " '/bouts/76963/',\n",
       " '/bouts/76962/',\n",
       " '/bouts/76742/',\n",
       " '/bouts/75341/',\n",
       " '/bouts/68648/',\n",
       " '/bouts/67875/',\n",
       " '/bouts/60955/',\n",
       " '/bouts/60970/',\n",
       " '/bouts/58695/',\n",
       " '/bouts/60968/',\n",
       " '/bouts/60388/',\n",
       " '/bouts/60483/',\n",
       " '/bouts/60953/',\n",
       " '/bouts/60964/',\n",
       " '/bouts/59216/',\n",
       " '/bouts/60951/',\n",
       " '/bouts/60962/',\n",
       " '/bouts/60949/',\n",
       " '/bouts/60957/',\n",
       " '/bouts/59173/',\n",
       " '/bouts/60638/',\n",
       " '/bouts/43604/',\n",
       " '/bouts/46000/',\n",
       " '/bouts/49725/',\n",
       " '/bouts/48932/',\n",
       " '/bouts/46004/',\n",
       " '/bouts/45257/',\n",
       " '/bouts/26993/',\n",
       " '/bouts/26751/',\n",
       " '/bouts/26996/',\n",
       " '/bouts/28453/',\n",
       " '/bouts/20826/',\n",
       " '/bouts/8857/',\n",
       " '/bouts/8219/',\n",
       " '/bouts/8500/',\n",
       " '/bouts/8250/',\n",
       " '/bouts/6924/',\n",
       " '/bouts/6164/',\n",
       " '/bouts/6158/',\n",
       " '/bouts/5040/',\n",
       " '/bouts/5956/',\n",
       " '/bouts/4227/',\n",
       " '/bouts/4250/',\n",
       " '/bouts/4327/',\n",
       " '/bouts/4632/',\n",
       " '/bouts/4326/',\n",
       " '/bouts/4509/',\n",
       " '/bouts/4285/',\n",
       " '/bouts/4021/',\n",
       " '/bouts/4007/',\n",
       " '/bouts/3197/']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetAllBouts(str(3393))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllScores(teamID, teamName):\n",
    "    scoreframes = []\n",
    "    bouts = GetAllBouts(teamID)\n",
    "    hp = HTMLTableParser()\n",
    "    for bout in bouts:\n",
    "        jampage = \"http://flattrackstats.com\"+bout+\"jams\"\n",
    "        \n",
    "        isAway = False \n",
    "        response = requests.get(jampage)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        for link in soup.findAll('title'):\n",
    "            fulltitle = link.get_text()\n",
    "            substr = fulltitle[fulltitle.find(':')+1 : fulltitle.find('(')]\n",
    "            if teamName in substr:\n",
    "                isAway = True\n",
    "        \n",
    "        scores = hp.parse_url_todf(jampage)[0].iloc[:,1:-1]\n",
    "        scores.loc[np.c_[scores.index[1::2].tolist(),scores.index[0:-1:2].tolist()].reshape(-1)]\n",
    "        \n",
    "        #del scores[0]\n",
    "        #print(scores)\n",
    "        scoreframes.append(scores)\n",
    "    allScores = pd.concat(scoreframes)\n",
    "    #print(allScores)\n",
    "    return(allScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllLineups(teamID, teamName):\n",
    "    lineupframes = []\n",
    "    bouts = GetAllBouts(teamID)\n",
    "    hp = HTMLTableParser()\n",
    "    for bout in bouts:\n",
    "        jampage = \"http://flattrackstats.com\"+bout+\"jams\"\n",
    "        \n",
    "        isAway = False \n",
    "        response = requests.get(jampage)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        for link in soup.findAll('title'):\n",
    "            fulltitle = link.get_text()\n",
    "            substr = fulltitle[fulltitle.find(':')+1 : fulltitle.find('(')]\n",
    "            if teamName in substr:\n",
    "                isAway = True\n",
    "                \n",
    "        lineups = hp.parse_url_todf(jampage)[1].iloc[:,1:-1]\n",
    "        \n",
    "        #put team of interest first (data is naturally in format (home, away) )\n",
    "        if isAway:\n",
    "            lineups.loc[np.c_[lineups.index[1::2].tolist(),lineups.index[0:-1:2].tolist()].reshape(-1)]\n",
    "        \n",
    "        lineupframes.append(lineups) \n",
    "        \n",
    "    #clean data    \n",
    "    allLineups = pd.concat(lineupframes)\n",
    "    allLineups.columns = ['Jammer','Jstats','B1','B2','B3','B4','NULL','jamscore','runscore']\n",
    "    del allLineups['NULL']\n",
    "    \n",
    "    allLineups = allLineups[~(allLineups.jamscore == 'Period 2')]\n",
    "    allLineups = allLineups[~(allLineups.jamscore.isnull())]\n",
    "    \n",
    "    #calc score differentials, for determining rankings\n",
    "    allLineups['jamscore'] = pd.to_numeric(allLineups['jamscore'])\n",
    "    allLineups['runscore'] = pd.to_numeric(allLineups['runscore'])\n",
    "    \n",
    "    allLineups['ScoreDiff'] = allLineups['jamscore'].diff(periods=-1)\n",
    "    allLineups.loc[1::2,\"ScoreDiff\"] = allLineups['jamscore'].diff(periods=1)\n",
    "    \n",
    "    #drop opposing team\n",
    "    allLineups = allLineups.iloc[::2]\n",
    "    allLineups = allLineups.reset_index()\n",
    "    del allLineups['index']\n",
    "    \n",
    "    return(allLineups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllPenalties(teamID, teamName):\n",
    "    penframes = []\n",
    "    bouts = GetAllBouts(teamID)\n",
    "    hp = HTMLTableParser()\n",
    "    for bout in bouts:\n",
    "        jampage = \"http://flattrackstats.com\"+bout+\"jams\"\n",
    "        \n",
    "        isAway = False \n",
    "        response = requests.get(jampage)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        for link in soup.findAll('title'):\n",
    "            fulltitle = link.get_text()\n",
    "            substr = fulltitle[fulltitle.find(':')+1 : fulltitle.find('(')]\n",
    "            if teamName in substr:\n",
    "                isAway = True\n",
    "        \n",
    "        pens = hp.parse_url_todf(jampage)[2].iloc[:,1:-1]\n",
    "        \n",
    "        if isAway:\n",
    "            pens.loc[np.c_[pens.index[1::2].tolist(),pens.index[0:-1:2].tolist()].reshape(-1)]\n",
    "\n",
    "        #del pens[0]\n",
    "        penframes.append(scores)\n",
    "    allPens = pd.concat(penframes)\n",
    "    #print(allPens)\n",
    "    return(allPens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetAllLineups(str(3393), 'Ohio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
