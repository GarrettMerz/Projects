{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this series of notebooks, I will attempt to do some introductory exploration of various roller derby statistics. We will use the publicly available stats on the FlatTrackStats website. First, I will build a table scraper tool using the BeautifulSoup4 package to parse the stats tables on the website. If not already installed, you will need pandas and BeautifulSoup4 in order to run this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import requests\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from bs4 import BeautifulSoup\n",
    "    from itertools import product\n",
    "    import urllib.request\n",
    "    import urllib.parse\n",
    "    import statistics\n",
    "    from statistics import mode\n",
    "    import collections\n",
    "    import re\n",
    "    \n",
    "    #First, define a class to parse HTML tables for bouts and players\n",
    "    \n",
    "    class HTMLTableParser:\n",
    "        def parse_url(self, url):\n",
    "            response = requests.get(url, timeout=None)\n",
    "            soup = BeautifulSoup(response.text, 'lxml')\n",
    "            return [(self.read_table(table)) for table in soup.find_all('table')]      \n",
    "        \n",
    "        def read_table(self, table_tag):\n",
    "            rowspans = []  # track pending rowspans\n",
    "            rows = table_tag.find_all('tr')\n",
    "\n",
    "            # first scan, see how many columns we need\n",
    "            colcount = 0\n",
    "            column_names=[]\n",
    "            for r, row in enumerate(rows):\n",
    "                cells = row.find_all(['td', 'th'], recursive=False)\n",
    "                colcount = max(\n",
    "                    colcount,\n",
    "                    sum(int(c.get('colspan', 1)) or 1 for c in cells[:-1]) + len(cells[-1:]) + len(rowspans))\n",
    "                # update rowspan bookkeeping; 0 is a span to the bottom. \n",
    "                rowspans += [int(c.get('rowspan', 1)) or len(rows) - r for c in cells]\n",
    "                rowspans = [s - 1 for s in rowspans if s > 1]\n",
    "\n",
    "            # it doesn't matter if there are still rowspan numbers 'active'; no extra\n",
    "            # rows to show in the table means the larger than 1 rowspan numbers in the\n",
    "            # last table row are ignored.    \n",
    "            # build an empty matrix for all possible cells\n",
    "            table = [[None] * colcount for row in rows]\n",
    "\n",
    "\n",
    "            # fill matrix from row data\n",
    "            rowspans = {}  # track pending rowspans, column number mapping to count\n",
    "            for row, row_elem in enumerate(rows):\n",
    "                span_offset = 0  # how many columns are skipped due to row and colspans \n",
    "                for col, cell in enumerate(row_elem.find_all(['td', 'th'], recursive=False)):\n",
    "                    # adjust for preceding row and colspans\n",
    "                    col += span_offset\n",
    "                    while rowspans.get(col, 0):\n",
    "                        span_offset += 1\n",
    "                        col += 1\n",
    "\n",
    "                    # fill table data\n",
    "                    rowspan = rowspans[col] = int(cell.get('rowspan', 1)) or len(rows) - row\n",
    "                    colspan = int(cell.get('colspan', 1)) or colcount - col\n",
    "                    # next column is offset by the colspan\n",
    "                    span_offset += colspan - 1\n",
    "                    value = cell.get_text()\n",
    "                    points = len(cell.find_all(\"div\", {\"class\": \" point\"}))\n",
    "                    pens = cell.find_all(\"div\", {\"class\": \"penalty major\"})  \n",
    "                    if (value == '' or value == '&nbsp') and points != '':\n",
    "                        value = str(points)\n",
    "                    if len(pens) > 0:\n",
    "                        value = ''\n",
    "                        for pen in pens:\n",
    "                            value += pen.find_all(text=True, recursive=False)[0] + \" \"\n",
    "                    if len(cell.find_all(\"div\", {\"class\": \"lead\"}))== 1:\n",
    "                        if value == \"0\": value = \"\"\n",
    "                        value += \"Lead \"\n",
    "                    if len(cell.find_all(\"div\", {\"class\": \"leadloss\"}))== 1:\n",
    "                        if value == \"0\": value = \"\"\n",
    "                        value += \"LeadLoss \"\n",
    "                    if len(cell.find_all(\"div\", {\"class\": \"lost\"}))== 1:\n",
    "                        if value == \"0\": value = \"\"\n",
    "                        value += \"LeadLoss \"                   \n",
    "                    if len(cell.find_all(\"div\", {\"class\": \"call\"}))== 1:\n",
    "                        if value == \"0\": value = \"\"\n",
    "                        value += \"call \"\n",
    "                    if len(cell.find_all(\"div\", {\"class\": \"nopass\"}))== 1:\n",
    "                        if value == \"0\": value = \"\"\n",
    "                        value += \"np \"    \n",
    "                    if len(cell.find_all(\"div\", {\"class\": \"starpass\"}))== 1:\n",
    "                        if value == \"0\": value = \"\"\n",
    "                        value += \"sp \"    \n",
    "                    for drow, dcol in product(range(rowspan), range(colspan)):\n",
    "                        try:\n",
    "                            table[row + drow][col + dcol] = value\n",
    "                            rowspans[col + dcol] = rowspan\n",
    "                        except IndexError:\n",
    "                            # rowspan or colspan outside the confines of the table\n",
    "                            pass\n",
    "\n",
    "                # update rowspan bookkeeping\n",
    "                rowspans = {c: s - 1 for c, s in rowspans.items() if s > 1}\n",
    "            npt = np.array(table)\n",
    "            #df = pd.DataFrame(np.array(table), column_names) \n",
    "            return table\n",
    "\n",
    "        def parse_url_todf(self, url):\n",
    "            tables = self.parse_url(url)\n",
    "            dfs = []\n",
    "            if \"combos\" in url:\n",
    "                for table in tables:\n",
    "                    headers = table.pop(0)\n",
    "                    df = pd.DataFrame(np.array(table), columns=np.array(headers))    \n",
    "                    dfs.append(df)\n",
    "            if \"teams\" in url:\n",
    "                for table in tables:\n",
    "                    headers = table.pop(0)\n",
    "                    df = pd.DataFrame(np.array(table), columns=np.array(headers))    \n",
    "                    dfs.append(df)\n",
    "            if \"jams\" in url:\n",
    "                for table in tables:\n",
    "                    headers = table.pop(0)\n",
    "                    df = pd.DataFrame(np.array(table), columns=np.array(headers))    \n",
    "                    dfs.append(df)        \n",
    "            else:\n",
    "                headers = tables[0]\n",
    "                headersnew = []\n",
    "                for header in headers:\n",
    "                    headernew = [i for i in header if i] \n",
    "                    headersnew.append(headernew)\n",
    "                for i in range(len(tables)-1):\n",
    "                    df = pd.DataFrame(np.array(tables[i+1]), columns=headersnew[i])    \n",
    "                    dfs.append(df)\n",
    "                \n",
    "            return dfs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a function to get all of a team's bouts from the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllBouts(teamID):\n",
    "    npages = 0\n",
    "    links=[]\n",
    "    \n",
    "    base_url = \"http://www.flattrackstats.com/teams/\"+teamID+\"/bouts\"\n",
    "    text = urllib.request.urlopen(base_url, timeout=None)\n",
    "    base_soup = BeautifulSoup(text)\n",
    "    \n",
    "    for listitem in base_soup.findAll('li', class_=\"pager-last last\"):\n",
    "        npages = int(listitem.findAll('a')[0]['href'][-1])\n",
    "    \n",
    "    \n",
    "    for page in range(0,npages):\n",
    "        url = \"http://www.flattrackstats.com/teams/\"+teamID+\"/bouts?page=\"+str(page)\n",
    "        text = urllib.request.urlopen(url, timeout=None)\n",
    "        soup = BeautifulSoup(text)\n",
    "        for link in soup.findAll('a', class_=\"boutlink has-stats\"):\n",
    "            linkname = link['href']\n",
    "            linksize = len(linkname)\n",
    "            if \"node\" not in link['href']:\n",
    "                linkstub = linkname[:linksize-8]\n",
    "            else: linkstub = \"/bouts\"+linkname[5:]+\"/\"\n",
    "            links.append(linkstub)\n",
    "                \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GetAllBouts(str(3637))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make some functions to read the data from the bouts page (one such page is here: http://flattrackstats.com/bouts/55689/jams).\n",
    "\n",
    "The first will be a function to read the table of points scored in each jam, logged per lap. This is similar in format to what is recorded on the track. Let's make sure to drop the opposing team's scores from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllScores(teamID, teamName):\n",
    "    scoreframes = []\n",
    "    bouts = GetAllBouts(teamID)\n",
    "    hp = HTMLTableParser()\n",
    "    for bout in bouts:\n",
    "        jampage = \"http://www.flattrackstats.com/\"+bout+\"jams\"\n",
    "        \n",
    "        isAway = False \n",
    "        response = requests.get(jampage, timeout = None)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        for link in soup.findAll('title'):\n",
    "            fulltitle = link.get_text()\n",
    "            substr = fulltitle[fulltitle.find(':')+1 : fulltitle.find('(')]\n",
    "            if teamName in substr:\n",
    "                isAway = True\n",
    "        \n",
    "        scores = hp.parse_url_todf(jampage)[1].iloc[:,1:-1]\n",
    "        scores.loc[np.c_[scores.index[1::2].tolist(),scores.index[0:-1:2].tolist()].reshape(-1)]\n",
    "        \n",
    "        #del scores[0]\n",
    "        #print(scores)\n",
    "        scoreframes.append(scores)\n",
    "    allScores = pd.concat(scoreframes)\n",
    "    #drop opposing team\n",
    "    allScores = allScores.iloc[::2]\n",
    "    allScores = allScores.reset_index()\n",
    "    del allScores['index']\n",
    "    #print(allScores)\n",
    "    return(allScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's make a function to get the table recording who played in each jam, and what the cumulative score, jam score, and score differential (my_team - opposing_team) was for that jam. Again, let's drop the opposing team's lineups. This is the function that will give us most of our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllLineups(teamID, teamName):\n",
    "    lineupframes = []\n",
    "    bouts = GetAllBouts(teamID)\n",
    "    hp = HTMLTableParser()\n",
    "    for bout in bouts:\n",
    "        jampage = \"http://www.flattrackstats.com/\"+bout+\"jams\"\n",
    "        \n",
    "        isAway = False \n",
    "        response = requests.get(jampage, timeout = None)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        for link in soup.findAll('title'):\n",
    "            fulltitle = link.get_text()\n",
    "            substr = fulltitle[fulltitle.find(':')+1 : fulltitle.find('(')]\n",
    "            if teamName in substr:\n",
    "                isAway = True        \n",
    "        lineups = hp.parse_url_todf(jampage)[2].iloc[:,1:-1]\n",
    "        \n",
    "        #put team of interest first (data is naturally in format (home, away) )\n",
    "        if isAway:\n",
    "            lineups = lineups.loc[np.c_[lineups.index[1::2].tolist(),lineups.index[0:-1:2].tolist()].reshape(-1)]\n",
    "        lineupframes.append(lineups) \n",
    "        \n",
    "    #clean data    \n",
    "    allLineups = pd.concat(lineupframes)\n",
    "    allLineups.columns = ['Jammer','Jstats','B1','B2','B3','B4','NULL','jamscore','runscore']\n",
    "    del allLineups['NULL']\n",
    "    \n",
    "    allLineups = allLineups[~(allLineups.jamscore == 'Period 2')]\n",
    "    allLineups = allLineups[~(allLineups.jamscore.isnull())]\n",
    "    \n",
    "    #calc score differentials, for determining rankings\n",
    "    allLineups['jamscore'] = pd.to_numeric(allLineups['jamscore'])\n",
    "    allLineups['runscore'] = pd.to_numeric(allLineups['runscore'])\n",
    "    \n",
    "    allLineups['ScoreDiff'] = allLineups['jamscore'].diff(periods=-1)\n",
    "    \n",
    "    #drop opposing team\n",
    "    allLineups = allLineups.iloc[::2]\n",
    "    allLineups = allLineups.reset_index()\n",
    "    del allLineups['index']\n",
    "    \n",
    "    return(allLineups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's make a function to get the penalties per jam. This will need to be cross-referenced with the lineups table in order to determine who got what penalties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllPenalties(teamID, teamName):\n",
    "    penframes = []\n",
    "    bouts = GetAllBouts(teamID)\n",
    "    hp = HTMLTableParser()\n",
    "    for bout in bouts:\n",
    "        jampage = \"http://www.flattrackstats.com/\"+bout+\"jams\"\n",
    "        \n",
    "        isAway = False \n",
    "        response = requests.get(jampage, timeout=None)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        for link in soup.findAll('title'):\n",
    "            fulltitle = link.get_text()\n",
    "            substr = fulltitle[fulltitle.find(':')+1 : fulltitle.find('(')]\n",
    "            if teamName in substr:\n",
    "                isAway = True\n",
    "        \n",
    "        pens = hp.parse_url_todf(jampage)[3].iloc[:,1:-1]\n",
    "        \n",
    "        if isAway:\n",
    "            pens.loc[np.c_[pens.index[1::2].tolist(),pens.index[0:-1:2].tolist()].reshape(-1)]\n",
    "\n",
    "        #del pens[0]\n",
    "        penframes.append(scores)\n",
    "    allPens = pd.concat(penframes)\n",
    "    #print(allPens)\n",
    "    return(allPens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lieu of rankings like ELO, let's just use an average of the score differential for each blocker (something like ELO would be better, but cumbersome to caclulate right now). Let's get an expanding average of the blocker's point differential (that is, after a given jam, the point differential for each jam the blocker has played in, averaged over all the times they have played).\n",
    "\n",
    "After calculating the expanding averages, let's also drop all jams for which one or more blockers involved hasn't played in at least 12 jams (that is, roughly one half a bout) from the dataset. This gives each blocker's average score differential a chance to stabilize. This block also has some other functions that might be useful for calculating the useful metrics for each jam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExpandingAverages(teamID, teamName):\n",
    "    lineups = GetAllLineups(teamID,teamName)\n",
    "    allBlockers = (lineups['B1'].append(lineups['B2']).append(lineups['B3']).append(lineups['B4'])).unique()\n",
    "    #print(allBlockers, len(allBlockers))\n",
    "    blockerCols = lineups[['B1','B2','B3','B4']]\n",
    "    #print(blockerCols)\n",
    "    blockerlist = pd.concat([pd.get_dummies(blockerCols[col]) for col in blockerCols.columns], axis = 1)\n",
    "    indicators = blockerlist.groupby(by=blockerlist.columns, axis=1).sum()\n",
    "    scorediffs = indicators.mul(lineups['ScoreDiff'], axis=0)\n",
    "    #don't include unplayed jams\n",
    "    scorediffs.replace(0, np.nan, inplace=True)\n",
    "    runningmean = scorediffs.expanding(1).mean()\n",
    "    runningmean.replace(np.nan, 0, inplace=True)\n",
    "    pd.set_option('display.max_columns', 58)  # or 1000\n",
    "    pd.set_option('display.max_rows', 20)  # or 1000\n",
    "    pd.set_option('display.max_colwidth', 15)  # or 199\n",
    "    #test2 = pd.concat([pd.get_dummies(blockerCols[col]) for col in blockerCols.columns], axis=1)\n",
    "    #test = lineups.stack().str.get_dummies(columns =['B1','B2','B3','B4']).sum(level=0)\n",
    "    return(runningmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function just gets a player's running score differential (i.e., if a player scores +1 and then -1, after those two jams,\n",
    "# it returns zero)\n",
    "\n",
    "def RunningDiffs(teamID, teamName):\n",
    "    lineups = GetAllLineups(teamID,teamName)\n",
    "    allBlockers = (lineups['B1'].append(lineups['B2']).append(lineups['B3']).append(lineups['B4'])).unique()\n",
    "    #print(allBlockers, len(allBlockers))\n",
    "    blockerCols = lineups[['B1','B2','B3','B4']]\n",
    "    #print(blockerCols)\n",
    "    blockerlist = pd.concat([pd.get_dummies(blockerCols[col]) for col in blockerCols.columns], axis = 1)\n",
    "    indicators = blockerlist.groupby(by=blockerlist.columns, axis=1).sum()\n",
    "    scorediffs = indicators.mul(lineups['ScoreDiff'], axis=0)\n",
    "    scorediffs.replace(0, np.nan, inplace=True)\n",
    "    pd.set_option('display.max_columns', 58)  # or 1000\n",
    "    pd.set_option('display.max_rows', 20)  # or 1000\n",
    "    pd.set_option('display.max_colwidth', 15)  # or 199\n",
    "    #test2 = pd.concat([pd.get_dummies(blockerCols[col]) for col in blockerCols.columns], axis=1)\n",
    "    #test = lineups.stack().str.get_dummies(columns =['B1','B2','B3','B4']).sum(level=0)\n",
    "    return(scorediffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns a running list of how much a given jam changes a player's average\n",
    "\n",
    "def AvgChangeFromJam(teamID, teamName):\n",
    "    avgs = ExpandingAverages(teamID, teamName)\n",
    "    avgswzero = pd.DataFrame([[0.0] * len(avgs.columns)], columns=avgs.columns)\n",
    "    avgs = avgswzero.append(avgs, ignore_index=True)\n",
    "    deltas = avgs.diff()\n",
    "    deltas = deltas.drop([0])\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns a list of how many total jams a player has played at a particular time\n",
    "\n",
    "def JamsPlayed(teamID, teamName):\n",
    "    lineups = GetAllLineups(teamID,teamName)\n",
    "    allBlockers = (lineups['B1'].append(lineups['B2']).append(lineups['B3']).append(lineups['B4'])).unique()\n",
    "    #print(allBlockers, len(allBlockers))\n",
    "    blockerCols = lineups[['B1','B2','B3','B4']]\n",
    "    #print(blockerCols)\n",
    "    blockerlist = pd.concat([pd.get_dummies(blockerCols[col]) for col in blockerCols.columns], axis = 1)\n",
    "    indicators = blockerlist.groupby(by=blockerlist.columns, axis=1).sum()\n",
    "    indicators.replace(0, np.nan, inplace=True)\n",
    "    jamtot = indicators.expanding(1).sum()\n",
    "    return(jamtot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns a list of all jams for which any player involved has not played N jams,\n",
    "#as well as a list of blockers who play a total of fewer than N jams.\n",
    "\n",
    "def GetBadJamsAndBlockers(teamID, teamName, N=12):\n",
    "    lineups = GetAllLineups(teamID,teamName)\n",
    "    jp = JamsPlayed(teamID,teamName)\n",
    "    allBlockers = (lineups['B1'].append(lineups['B2']).append(lineups['B3']).append(lineups['B4'])).unique()\n",
    "    #print(allBlockers, len(allBlockers))\n",
    "    blockerCols = lineups[['B1','B2','B3','B4']]\n",
    "    #print(blockerCols)\n",
    "    badjamlist = []\n",
    "    \n",
    "    for jamnum in range(len(jp)):\n",
    "        for col in blockerCols.columns:\n",
    "            blockername = blockerCols.loc[jamnum,col]\n",
    "            jamcount = jp.loc[jamnum,blockername]\n",
    "            if (jamcount < N): \n",
    "                badjamlist.append(jamnum)\n",
    "    \n",
    "    mask = jp.iloc[-1] < N\n",
    "    badjp = jp.loc[:, mask]\n",
    "    badblockerlist=list(badjp.columns)\n",
    "    \n",
    "    badjamarray = np.array(badjamlist)\n",
    "    badjamarray=np.unique(badjamarray)\n",
    "    \n",
    "    return(badjamarray.tolist(),badblockerlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got all our functions, let's do some preprocessing. First, we want to make sure that the ExpandingAverage is a relatively stable metric of a player's skill, and determine approximately the number of jams played that is needed for the metric to be valid. Let's look at Killamazoo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Remove bad jams and blockers\n",
    "\n",
    "def ExpandingAveragesCleaned(teamID, teamName,N=12):\n",
    "    avgs = ExpandingAverages(teamID, teamName)\n",
    "    badjams,badblockers = GetBadJamsAndBlockers(teamID, teamName,N)\n",
    "    avgs= avgs.drop(labels=badjams, axis=0)\n",
    "    avgs= avgs.drop(labels=badblockers, axis=1)\n",
    "    \n",
    "    return(avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exa12= ExpandingAveragesCleaned(str(3637),'Killamazoo',12)\n",
    "#exa12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exa20= ExpandingAveragesCleaned(str(3637),'Killamazoo',20)\n",
    "#exa20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ExpandingAverages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-eeb0ad5f933a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexa30\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mExpandingAveragesCleaned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3637\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Killamazoo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexa30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d4700444277e>\u001b[0m in \u001b[0;36mExpandingAveragesCleaned\u001b[0;34m(teamID, teamName, N)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mExpandingAveragesCleaned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteamID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteamName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mavgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExpandingAverages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteamID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteamName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mbadjams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbadblockers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetBadJamsAndBlockers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteamID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteamName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mavgs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mavgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbadjams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ExpandingAverages' is not defined"
     ]
    }
   ],
   "source": [
    "#exa30= ExpandingAveragesCleaned(str(3637),'Killamazoo',30)\n",
    "#exa30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's use 12 as our minimum number of jams and plot the expanding averages for Javelin, one of Kalamazoo's longest-playing blockers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exa20[\"Javelin\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay great! This seems to be pretty good- we can see her steadily improving over time, starting out circa -5 and getting to a differential of zero. This is a solid metric. If we wanted to, we could compare this to ELO and other ranking systems to determine accuracy, calculating how predictive the various metrics are- but this one is easy to calculate and seems decent enough for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's make a function to get all the teams and their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNameFromID(teamID):\n",
    "    npages = 0\n",
    "    links=[]\n",
    "    scoreframes = []\n",
    "    allteams=[]\n",
    "    bouts = GetAllBouts(teamID)\n",
    "    hp = HTMLTableParser()\n",
    "    for i,bout in enumerate(bouts):\n",
    "        jampage = \"http://www.flattrackstats.com/\"+bout+\"jams\" \n",
    "        isAway = False \n",
    "        response = requests.get(jampage, timeout=None)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        for link in soup.findAll('title'):\n",
    "            fulltitle = link.get_text()\n",
    "            awayteam = fulltitle[fulltitle.find(': ')+1 : fulltitle.find(' (')]\n",
    "            hometeam = fulltitle[fulltitle.find('@ ')+1 : fulltitle.find(' (', fulltitle.find(' (') + 1)]\n",
    "            allteams.append(hometeam)\n",
    "            allteams.append(awayteam)\n",
    "        if i > 10: break    \n",
    "    if (allteams==[]): teamname = \"NO_STATS\"        \n",
    "    else: teamname=mode(allteams)    \n",
    "    \n",
    "    #print(teamname)            \n",
    "    return teamname        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllTeamsAndNames():\n",
    "    npages = 0\n",
    "    IDs_All=[]\n",
    "    Names_All=[]\n",
    "    IDs=[]\n",
    "    Names=[]\n",
    "    \n",
    "    base_url = \"http://www.flattrackstats.com/teams/results/wftda-usa\"\n",
    "    text = urllib.request.urlopen(base_url, timeout=None)\n",
    "    base_soup = BeautifulSoup(text)\n",
    "    \n",
    "    for listitem in base_soup.findAll('li', class_=\"pager-last last\"):\n",
    "        npages = int(listitem.findAll('a')[0]['href'][-1])\n",
    "    \n",
    "    \n",
    "    for page in range(0,npages):\n",
    "        url = base_url+\"?page=\"+str(page)\n",
    "        text = urllib.request.urlopen(url, timeout=None)\n",
    "        soup = BeautifulSoup(text)\n",
    "        for link in soup.findAll('a', class_=''):\n",
    "            linkname = link['href']\n",
    "            #print(linkname)\n",
    "            linksize = len(linkname)\n",
    "            if \"node\" in link['href']:\n",
    "                linkstub = linkname[6:linksize]\n",
    "                #print(linkstub)\n",
    "                IDs_All.append(linkstub)\n",
    "            elif \"overview\" in link['href']:\n",
    "                linkstub = linkname[7:linksize-9]\n",
    "                #print(linkstub)\n",
    "                IDs_All.append(linkstub)\n",
    "            \n",
    "    for ID in IDs_All:\n",
    "        #print(ID)\n",
    "        name = getNameFromID(ID)\n",
    "        #print(name)\n",
    "        Names_All.append(name)\n",
    "   \n",
    "    for ID, name in zip(IDs_All,Names_All):\n",
    "        if name == \"NO_STATS\": continue\n",
    "        IDs.append(ID)    \n",
    "        Names.append(name)\n",
    "\n",
    "    return IDs,Names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
