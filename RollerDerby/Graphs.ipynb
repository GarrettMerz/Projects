{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataset, we can start to do some actual analysis. I'm going to be attempting to replicate the methodology of this paper:\n",
    "\n",
    "Sapienza, Anna and Goyal, Palash and Ferrara, Emilio. Deep Neural Networks for Optimal Team Composition. Frontiers in Big Data, vol 2. Jun 2019. https://arxiv.org/abs/1805.03285 \n",
    "\n",
    "While roller derby and esports games like League of Legends obviously are very different, in many ways, they can be treated similarly- each League match and individual jam of a derby bout consists of a team of 5 players with different defined roles attempting to achieve an objective while slowing the opposing team's attempt to achieve theirs.\n",
    "\n",
    "A derby bout (game) consists of a series of many individual jams. Each team forwards a defensive line of four \"blockers\" and an offensive line of one \"jammer\". The jammer scores points by passing through the \"pack\" of blockers- one initial non-scoring pass through the pack is required, and then one point is earned for each of the opposing team's blockers that the jammer passes on subsequent laps. Each jam can run for a set amount of time, but the jammer that is the first to complete the non-scoring pass (\"lead jammer\") can choose to end the jam early. In addition, the jammer can hand off their jammer status to one special blocker on each team called a \"pivot\" by passing the special helmet cover that the jammer wears. This is the general gist of the sport- in many ways, it's similar to the playground game \"Red Rover\", but on wheels.\n",
    "\n",
    "Naturally, when the blockers try to stop the jammer, things can get scrappy! Various penalties are given when a player shoves another in an illegal manner, when a blocker strays too far from the pack, when a player goes out of bounds, when a blocker makes an illegal formation (such as linking arms with another blocker), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's pick a team. I'll use the Kalamazoo Derby Darlins, the team I've announced for for the past few years. \n",
    "\n",
    "In this analysis, I'm going to make some assumptions.\n",
    "-First, that the fundamental unit of derby is not the bout, but the jam. Each jam is unique, and may have starting conditions determined by the preceding jam, but ultimately, for the purposes of this analysis, the only influence jam 1 may have on a jam like jam 20 is player stamina (N.B.: sometimes players can still be in the penalty box from previous jams, so this is not strictly correct! but it's probably correct enough for what we'd like to test here). This means that I will update a player's \"rating\" each jam rather than each bout.\n",
    "\n",
    "-Second, that the \"figure of merit\" to determine the performance of a jammer is the total number of points they score in a jam, but that the \"figure of merit\" to determine the performance of a blocker line is the difference between their jammer's score and the opposing jammer's score. A good blocker line is able to slow the opposing jammer substantially while also letting their own through.\n",
    "\n",
    "-Third: the rules of roller derby change often, as the sport is still relatively new. For instance- at one point, jammers scored an additional point for passing the opposing team's jammer as well as blockers. I'm assuming that we can largely treat them as constant- otherwise, I'm not sure we'll have enough stats.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import trueskill\n",
    "from bs4 import BeautifulSoup\n",
    "from itertools import product\n",
    "from urllib.request import urlopen\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import to_agraph \n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import random\n",
    "from random import sample\n",
    "\n",
    "import nbimporter\n",
    "import Webscraper as wsc\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "teamID=str(3637)\n",
    "teamName='Killamazoo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstats(teamID,teamName):\n",
    "#First, get the lineups for each jam KDD has stats available for.\n",
    "    AllLineups = wsc.GetAllLineups(teamID, teamName)\n",
    "\n",
    "# Also, get expanding average of score differentials for each jam. We'll use a player's\n",
    "# average score differential after a given jam as a proxy for their skill ranking as measured\n",
    "# after playing that jam.\n",
    "\n",
    "    AllAvgs = wsc.ExpandingAverages(teamID, teamName)\n",
    "    badjams,badblockers = wsc.GetBadJamsAndBlockers(teamID, teamName,20)\n",
    "    \n",
    "    return AllLineups,AllAvgs,badjams,badblockers\n",
    "#print(badjams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's only look at blockers for now, since they interact most closely with each other. Matching jammers to blocker lines is a different question than composing the lines themselves, since interplay is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(AllLineups, AllAvgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's build the short and long term play networks described in the paper. We'll also need to prune them to remove isolated nodes and edges corresponding to less than two co-play jams. As an aside, there's a pretty clear typo in the paper: the long-term play network should drop off with time since last co-play, not increase (i.e., there should be a negative sign in the exponent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetGraphs(teamID,teamName):\n",
    "    \n",
    "    AllLineups,AllAvgs,badjams,badblockers = getstats(teamID,teamName)\n",
    "    blockerlines = AllLineups[['B1', 'B2', 'B3', 'B4']]\n",
    "    #print(blockerlines)\n",
    "\n",
    "    STjams=[]\n",
    "    for jamnum in range(len((blockerlines.index))):\n",
    "\n",
    "        if (jamnum in badjams): continue\n",
    "        G = nx.complete_graph(4, nx.DiGraph())\n",
    "        blockers = blockerlines.iloc[jamnum].to_list()\n",
    "        mapping = dict(zip(G, blockers))\n",
    "        G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "        for edge in G.edges():\n",
    "            weight = AllAvgs.iloc[jamnum][edge[0]]-AllAvgs.iloc[jamnum-1][edge[0]]\n",
    "            #print(weight)\n",
    "            G[edge[0]][edge[1]]['weight'] = weight\n",
    "            STjams.append(G)\n",
    "\n",
    "    STGraph = nx.DiGraph()\n",
    "    for jam in STjams:\n",
    "        for edge in jam.edges():\n",
    "            if STGraph.has_edge(*edge):\n",
    "                weightsum = jam.get_edge_data(*edge)['weight'] + STGraph.get_edge_data(*edge)['weight'] \n",
    "                STGraph[edge[0]][edge[1]]['weight'] = weightsum\n",
    "            else: \n",
    "                #print(\"no edge yet\")\n",
    "                STGraph.add_edge(*edge[:2])\n",
    "                STGraph[edge[0]][edge[1]]['weight'] = 0\n",
    "\n",
    "    #Now get LTGraph.            \n",
    "    #Get nodes and edges from the STGraph, remove weights\n",
    "    LTGraph = STGraph.to_directed()\n",
    "\n",
    "    for edge in LTGraph.edges():\n",
    "        LTGraph[edge[0]][edge[1]]['weight'] = 0\n",
    "        LTGraph[edge[0]][edge[1]]['jamssince'] = 0\n",
    "        LTGraph[edge[0]][edge[1]]['totalcoplays'] = 0\n",
    "\n",
    "\n",
    "    #Add a new edge feature: \"jams since last co-play\" that updates each jam, and use it to get the weights    \n",
    "\n",
    "    for jamnum in range(len((blockerlines.index))):\n",
    "        #get all edges in jam\n",
    "        G = nx.complete_graph(4, nx.DiGraph())\n",
    "        blockers = blockerlines.iloc[jamnum].to_list()\n",
    "        mapping = dict(zip(G, blockers))\n",
    "        G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "        #get all possible combos\n",
    "        for edge in LTGraph.edges():\n",
    "            #zero if they play together in this jam, increment otherwise\n",
    "            if edge in G.edges(): LTGraph[edge[0]][edge[1]]['jamssince'] = 0\n",
    "            else: LTGraph[edge[0]][edge[1]]['jamssince'] += 1\n",
    "\n",
    "        #get total number of co-play jams    \n",
    "        for edge in G.edges():    \n",
    "            if edge in LTGraph.edges(): LTGraph[edge[0]][edge[1]]['totalcoplays'] += 1\n",
    "        \n",
    "        if (jamnum in badjams): continue\n",
    "        \n",
    "        # Get all blockers in the jam, get all possible teammates\n",
    "        for node in G:\n",
    "            edges = LTGraph.out_edges(node)\n",
    "            for edge in edges:\n",
    "            # weight them by exp(-time) since last co-play: influence persists across jams but drops off with time\n",
    "                nomweight = AllAvgs.iloc[jamnum][edge[0]]-AllAvgs.iloc[jamnum-1][edge[0]]\n",
    "                #print(LTGraph[edge[0]][edge[1]]['jamssince'])\n",
    "                modifier = np.exp(-LTGraph[edge[0]][edge[1]]['jamssince'])\n",
    "                LTGraph[edge[0]][edge[1]]['weight'] += nomweight*modifier\n",
    "    \n",
    "    return STGraph,LTGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PruneGraphs(STGraph,LTGraph):\n",
    "   \n",
    "    #print(len(STGraph))\n",
    "    edges_to_prune=[]\n",
    "    nodes_to_prune=[]\n",
    "    \n",
    "    #drop all edges with fewer than two co-plays    \n",
    "    for edge in LTGraph.edges():\n",
    "        thisedge = LTGraph.get_edge_data(*edge)\n",
    "        #print(thisedge)\n",
    "        if LTGraph[edge[0]][edge[1]]['totalcoplays'] < 2: \n",
    "            edges_to_prune.append(edge)\n",
    "    \n",
    "    for edge in edges_to_prune:\n",
    "        STGraph.remove_edge(*edge)\n",
    "        LTGraph.remove_edge(*edge)\n",
    "\n",
    "    #get Largest Connected Component\n",
    "    #if(nx.strongly_connected_components(STGraph) == []): \n",
    "    #    largestSTGraph = []\n",
    "    #    largestLTGraph = [] \n",
    "    \n",
    "   # else:\n",
    "    largestSTGraph = max(nx.strongly_connected_components(STGraph), key=len)\n",
    "    largestLTGraph = max(nx.strongly_connected_components(LTGraph), key=len)\n",
    "    \n",
    "    #print(STGraph)\n",
    "    for node in LTGraph: \n",
    "        if node not in largestLTGraph: nodes_to_prune.append(node)\n",
    "            #print(node)\n",
    "            \n",
    "    for node in nodes_to_prune:\n",
    "        #print(node)\n",
    "        STGraph.remove_node(node)\n",
    "        LTGraph.remove_node(node)\n",
    "\n",
    "    return(STGraph,LTGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STGraph, LTGraph = GetGraphs(teamID,teamName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STpruned, LTpruned = PruneGraphs(STGraph, LTGraph)\n",
    "#print(nx.is_strongly_connected(STpruned))\n",
    "#nx.drawing.nx_pylab.draw_circular(STpruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAndWritePrunedGraphs(teamID,teamName):\n",
    "    STGraph, LTGraph = GetGraphs(teamID,teamName)\n",
    "    \n",
    "    try:\n",
    "        STpruned, LTpruned = PruneGraphs(STGraph, LTGraph)\n",
    "\n",
    "        #ST_relabel = nx.convert_node_labels_to_integers(STpruned)\n",
    "        #LT_relabel = nx.convert_node_labels_to_integers(LTpruned)\n",
    "\n",
    "        nx.write_weighted_edgelist(STpruned, \"Data/STGraphs/\"+teamID+\"STGraph.edgelist\", delimiter=\",,\")\n",
    "        nx.write_weighted_edgelist(LTpruned, \"Data/LTGraphs/\"+teamID+\"LTGraph.edgelist\", delimiter=\",,\")\n",
    "    \n",
    "    except: print(\"not enough data to get LCC!\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GetAndWritePrunedGraphs(str(3637),'Killamazoo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now make all STGraphs and LTGraphs\n",
    "\n",
    "IDs, names = wsc.getAllTeamsAndNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20988', '8003', '3636', '3422', '9248', '3420', '13529', '7876', '3433', '3399', '3424', '3418', '15073', '4737', '12607', '26170', '18437', '3404', '14228', '3464', '3397', '17350', '8143', '7521', '8059', '3402', '16730', '11127', '3419', '3437', '7928', '4740', '11444', '3414', '4742', '8142', '16731', '8141', '8087', '3463', '3642', '4744', '8140', '3395', '7870', '10187', '8052', '13834', '3427', '7511', '7813', '7696', '7608', '25344', '3432', '13840', '20989', '3400', '14613', '3444', '48273', '3625', '3431', '3471', '3644', '29611', '3392', '8044', '3435', '3430', '28777', '9085', '3406', '3457', '25351', '12621', '8138', '3465', '8731', '3396', '8095', '11351', '8086', '3466', '9086', '3411', '3640', '21447', '8137', '3626', '3426', '8047', '4036', '3413', '3412', '7825', '3643', '8073', '16733', '3456', '3447', '14233', '8127', '25640', '3421', '3646', '7244', '3627', '5916', '32345', '3647', '5917', '3467', '4292', '3637', '3407', '15020', '3470', '3639', '5918', '7745', '3416', '6738', '3425', '13612', '3443', '8046', '11255', '25759', '3453', '12502', '3428', '8542', '7593', '8610', '7815', '8105', '13528', '11525', '26479', '3438', '3445', '11403', '3629', '13401', '3429', '3454', '3423', '27351', '3393', '13100', '3450', '7247', '3446', '3452', '27179', '3468', '8002', '7761', '58599', '24211', '3394', '3401', '12490', '22848', '3415', '7614', '3641', '4291', '3403', '6740', '21262', '8103', '3459', '5919', '7822', '8628', '29706', '4741', '3405', '47144', '8132', '3409', '33110', '7845', '8124', '10178', '8118', '14194', '18716', '3638', '8894', '24511', '13403', '7848', '3633', '13732', '3449', '3469', '8131', '3635', '3648', '8102', '8101', '21403', '7248', '11470', '4738', '13397', '3417', '3458', '3462', '3440', '3408', '3624', '8057', '18376', '5920', '3398', '8048', '8661', '6742', '12233', '23027', '13957', '8518']\n",
      "[\" A'Salt Creek\", ' Acadiana', ' NEO', ' Alamo City', ' Albany', ' Angel City', ' Ann Arbor', ' Appalachian Rollergirls', ' Arch Rival', ' Arizona', ' Assassination', ' Atlanta', ' MRD: Unholy Rollers', ' Babe City', ' Diamond Divas', ' Bangor', ' Cereal Killers', ' Bay Area', ' Bay State Brawlers', ' Bellingham', ' Big Easy', ' Black Diamond', ' Black Rose Rollers', ' Black-n-Bluegrass', ' Blue Ridge Rollers', ' Boston', ' Boulder County', ' Brandywine', ' Brewcity', ' Burning River', ' Cajun Rollergirls', ' Cape Fear', ' Crushers', ' Carolina', ' Castle Rock', ' Mississippi Valley', ' Confluence', ' Cen-Tex', ' Shasta', ' Central Coast', ' Central NY', ' Charlotte', ' Charlottesville', ' Charm City', ' Chattanooga', ' Chemical Valley', ' Cherry City', ' DEAD: Superior Sirens', ' Cincinnati', ' Circle City', ' Classic City', ' Columbia', ' CoMo', ' Confluence', ' Connecticut', ' Cornfed', ' Crossroads City', ' Dallas', ' Dark River', ' DC', ' Dead River', ' Demolition', ' Denver', ' Derby City', ' Bakersfield', ' Team United', ' Detroit', ' Diamond State', ' Dixie', ' Dominion', ' LDV: Capital Corruption', ' Dub City', ' Duke', ' Dutchland', ' Paradise Roller Girls', ' Ohio Valley', ' Cen-Tex', ' Emerald City', ' Enchanted Mountain', ' Sin City', ' Fargo Moorhead', ' Rogue Rollergirls', ' Flint City', ' FoCo', ' Ft. Myers', ' Ft. Wayne', ' Fox City', ' Free State', ' Nashville', ' Garden State', ' Gem City', ' Glass City', ' Gold Coast', ' Gotham', ' Grand Raggidy', ' Granite State', ' Green Mt.', ' Greenville Derby Dames', ' Happy Valley', ' Hard Knox', ' Harrisburg', ' Black Rose Rollers', ' Hellions', ' First Settlement', ' Houston', ' Hudson Valley', ' Humboldt', ' ICT', ' Ithaca', ' WRD: Bonneville Bone Crushers', ' Jacksonville', ' Jersey Shore', ' Jet City', ' Junction City', ' Killamazoo', ' Kansas City', ' Lansing Derby', ' Humboldt', ' Lehigh Valley', ' Little City', ' Little Steel Derby Girls', ' Long Island', ' Lowcountry', ' Madison', ' Billings', ' Maine', ' Mason-Dixon', ' New Hampshire', ' Med City', ' Memphis', ' Mid-State', ' Minnesota', \" Brawlin' Betties\", ' Mississippi Valley', ' Mo-Kan', ' Molly Roger', ' Santa Cruz', ' Morgantown', ' Mother State', ' Muscogee', ' Naptown', ' Nashville', \" A'Salt Creek\", ' New Hampshire', ' Shore Points', ' No Coast', ' North Star', ' NW Arkansas', ' Northwest', ' Ohio', ' Ohio Valley', ' Okla. Victory', ' Old Capitol City', ' Oly', ' Omaha', ' Psycho City', ' Paradise Roller Girls', ' SK8R Dolls', ' Paradise Roller Girls', ' Peach State', ' Silicon Valley', ' Philly', ' Pikes Peak', ' Port Scandalous', ' Punishers', ' Providence', ' South Bend', ' Queen City', ' Oklahoma City', ' Rat City', ' Red Stick', ' Resurrection', ' Richland County Regulators', ' River City', ' Roc City', ' Rock Coast', ' Central Arkansas', \" Rockin' City\", ' Rocktown', ' Rocky Mtn.', ' Roe City Rollers', ' R.O.C.K.', ' Rose', ' Confluence', ' Sac City', ' St. Chux', ' Salisbury', ' Assault City', ' San Diego Starlettes', ' San Fernando', ' Santa Cruz', ' Savannah', ' Shasta', ' Shore Points', ' Sick Town', ' Silicon Valley', ' SINtral Valley', ' Sioux Falls', ' Slaughterhouse', ' SoCal Derby', ' Pueblo', ' Sonoma', ' Soul City', ' South Bend', ' Southern Delaware', ' So Ill', ' Spokannibals', ' Springfield', ' State College', ' Steel City', ' Suburbia', ' Tallahassee', ' Tampa', ' Texas', ' Chicago Outfit', ' Tragic City', ' Traverse City', ' Treasure Valley', ' Tucson', ' Twin City Derby Girls', ' Knockers', ' New River Valley', ' Undead Bettys', ' Unforgiven', ' V Town', ' Ventura']\n"
     ]
    }
   ],
   "source": [
    "print(IDs)\n",
    "print(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15073  MRD: Unholy Rollers\n",
      "not enough data to get LCC!\n",
      "26170  Bangor\n",
      "not enough data to get LCC!\n",
      "8142  Mississippi Valley\n",
      "not enough data to get LCC!\n",
      "16731  Confluence\n",
      "not enough data to get LCC!\n",
      "8087  Shasta\n",
      "not enough data to get LCC!\n",
      "8052  Cherry City\n",
      "not enough data to get LCC!\n",
      "13834  DEAD: Superior Sirens\n",
      "not enough data to get LCC!\n",
      "25344  Confluence\n",
      "not enough data to get LCC!\n",
      "3471  Derby City\n",
      "not enough data to get LCC!\n",
      "28777  LDV: Capital Corruption\n",
      "not enough data to get LCC!\n",
      "9085  Dub City\n",
      "not enough data to get LCC!\n",
      "12621  Ohio Valley\n",
      "not enough data to get LCC!\n",
      "8138  Cen-Tex\n",
      "not enough data to get LCC!\n",
      "21447  Free State\n",
      "not enough data to get LCC!\n",
      "3412  Grand Raggidy\n",
      "7825  Granite State\n",
      "3643  Green Mt.\n",
      "8073  Greenville Derby Dames\n",
      "16733  Happy Valley\n",
      "3456  Hard Knox\n",
      "3447  Harrisburg\n",
      "14233  Black Rose Rollers\n",
      "not enough data to get LCC!\n",
      "8127  Hellions\n",
      "25640  First Settlement\n",
      "3421  Houston\n",
      "3646  Hudson Valley\n",
      "7244  Humboldt\n",
      "3627  ICT\n",
      "5916  Ithaca\n",
      "32345  WRD: Bonneville Bone Crushers\n",
      "3647  Jacksonville\n",
      "5917  Jersey Shore\n",
      "not enough data to get LCC!\n",
      "3467  Jet City\n",
      "4292  Junction City\n",
      "3637  Killamazoo\n",
      "3407  Kansas City\n",
      "15020  Lansing Derby\n",
      "3470  Humboldt\n",
      "not enough data to get LCC!\n",
      "3639  Lehigh Valley\n",
      "5918  Little City\n",
      "7745  Little Steel Derby Girls\n",
      "3416  Long Island\n",
      "6738  Lowcountry\n",
      "3425  Madison\n",
      "13612  Billings\n",
      "3443  Maine\n",
      "8046  Mason-Dixon\n",
      "11255  New Hampshire\n",
      "25759  Med City\n",
      "3453  Memphis\n",
      "12502  Mid-State\n",
      "3428  Minnesota\n",
      "8542  Brawlin' Betties\n",
      "7593  Mississippi Valley\n",
      "not enough data to get LCC!\n",
      "8610  Mo-Kan\n",
      "7815  Molly Roger\n",
      "8105  Santa Cruz\n",
      "not enough data to get LCC!\n",
      "13528  Morgantown\n",
      "11525  Mother State\n",
      "26479  Muscogee\n",
      "3438  Naptown\n",
      "3445  Nashville\n",
      "11403  A'Salt Creek\n",
      "not enough data to get LCC!\n",
      "3629  New Hampshire\n",
      "13401  Shore Points\n",
      "3429  No Coast\n",
      "3454  North Star\n",
      "3423  NW Arkansas\n",
      "27351  Northwest\n",
      "3393  Ohio\n",
      "13100  Ohio Valley\n",
      "3450  Okla. Victory\n",
      "7247  Old Capitol City\n",
      "3446  Oly\n",
      "3452  Omaha\n",
      "27179  Psycho City\n",
      "3468  Paradise Roller Girls\n",
      "8002  SK8R Dolls\n",
      "7761  Paradise Roller Girls\n",
      "58599  Peach State\n",
      "24211  Silicon Valley\n",
      "not enough data to get LCC!\n",
      "3394  Philly\n",
      "3401  Pikes Peak\n",
      "12490  Port Scandalous\n",
      "not enough data to get LCC!\n",
      "22848  Punishers\n",
      "3415  Providence\n",
      "7614  South Bend\n",
      "3641  Queen City\n",
      "4291  Oklahoma City\n",
      "not enough data to get LCC!\n",
      "3403  Rat City\n",
      "6740  Red Stick\n",
      "21262  Resurrection\n",
      "8103  Richland County Regulators\n",
      "3459  River City\n",
      "5919  Roc City\n",
      "7822  Rock Coast\n",
      "8628  Central Arkansas\n",
      "not enough data to get LCC!\n",
      "29706  Rockin' City\n",
      "4741  Rocktown\n",
      "3405  Rocky Mtn.\n",
      "47144  Roe City Rollers\n",
      "8132  R.O.C.K.\n",
      "3409  Rose\n",
      "33110  Confluence\n",
      "not enough data to get LCC!\n",
      "7845  Sac City\n",
      "8124  St. Chux\n",
      "10178  Salisbury\n",
      "8118  Assault City\n",
      "14194  San Diego Starlettes\n",
      "18716  San Fernando\n",
      "3638  Santa Cruz\n",
      "8894  Savannah\n",
      "24511  Shasta\n",
      "13403  Shore Points\n",
      "7848  Sick Town\n",
      "not enough data to get LCC!\n",
      "3633  Silicon Valley\n",
      "13732  SINtral Valley\n",
      "3449  Sioux Falls\n",
      "3469  Slaughterhouse\n",
      "8131  SoCal Derby\n",
      "3635  Pueblo\n",
      "3648  Sonoma\n",
      "8102  Soul City\n",
      "8101  South Bend\n",
      "21403  Southern Delaware\n",
      "7248  So Ill\n",
      "11470  Spokannibals\n",
      "4738  Springfield\n",
      "13397  State College\n",
      "3417  Steel City\n",
      "3458  Suburbia\n",
      "3462  Tallahassee\n",
      "3440  Tampa\n",
      "3408  Texas\n",
      "3624  Chicago Outfit\n",
      "8057  Tragic City\n",
      "18376  Traverse City\n",
      "5920  Treasure Valley\n",
      "3398  Tucson\n",
      "8048  Twin City Derby Girls\n",
      "8661  Knockers\n",
      "6742  New River Valley\n",
      "not enough data to get LCC!\n",
      "12233  Undead Bettys\n",
      "23027  Unforgiven\n",
      "13957  V Town\n",
      "8518  Ventura\n"
     ]
    }
   ],
   "source": [
    "for ID,name in zip(IDs,names):\n",
    "    if path.exists(\"Data/STGraphs/\"+ID+\"STGraph.edgelist\"): continue\n",
    "    print(ID,name)\n",
    "    GetAndWritePrunedGraphs(str(ID),name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StandardizeGraphs():\n",
    "    STGraphFullUnNorm = nx.read_weighted_edgelist(\"Data/AllTeamsFullSTGraph.edgelist\", delimiter=\",,\")\n",
    "    LTGraphFullUnNorm = nx.read_weighted_edgelist(\"Data/AllTeamsFullLTGraph.edgelist\", delimiter=\",,\")\n",
    "    \n",
    "    STweights = []\n",
    "    LTweights = []\n",
    "    STweightsNew = []\n",
    "    LTweightsNew = [] \n",
    "\n",
    "    for node1, node2, data in STGraphFullUnNorm.edges(data=True):\n",
    "        STweights.append(data['weight'])\n",
    "    \n",
    "    for node1, node2, data in LTGraphFullUnNorm.edges(data=True):\n",
    "        LTweights.append(data['weight'])\n",
    "        \n",
    "    #Check Freqs  \n",
    "    #frequency, bins = np.histogram(STweights, bins=100, range=[-50, 50])  \n",
    "    #for b, f in zip(bins[1:], frequency):\n",
    "    #    print(round(b, 1),f)\n",
    "    #frequency, bins = np.histogram(LTweights, bins=100, range=[-50, 50])  \n",
    "    #for b, f in zip(bins[1:], frequency):\n",
    "    #    print(round(b, 1),f)     \n",
    "    \n",
    "    #Both are Gaussian, so we can safely standardize inputs without dramatically altering the structure of the data.\n",
    "    \n",
    "    STsig = statistics.stdev(STweights)\n",
    "    STmean = statistics.mean(STweights)\n",
    "    LTsig = statistics.stdev(LTweights)\n",
    "    LTmean = statistics.mean(LTweights)\n",
    "    \n",
    "    for node1, node2, data in STGraphFullUnNorm.edges(data=True):\n",
    "        data['weight'] = (data['weight'] - STmean)/STsig\n",
    "        STweightsNew.append(data['weight'])\n",
    "        \n",
    "    for node1, node2, data in LTGraphFullUnNorm.edges(data=True):\n",
    "        data['weight'] = (data['weight'] - LTmean)/LTsig\n",
    "        LTweightsNew.append(data['weight'])\n",
    "        \n",
    "    #Check Freqs  \n",
    "    #frequency, bins = np.histogram(LTweightsNew, bins=20, range=[-10, 10])  \n",
    "    #for b, f in zip(bins[1:], frequency):\n",
    "    #    print(round(b, 1),f)\n",
    "    \n",
    "    nx.write_weighted_edgelist(STGraphFullUnNorm, \"Data/AllTeamsFullSTGraphStandardized.edgelist\", delimiter=\",,\")\n",
    "    nx.write_weighted_edgelist(LTGraphFullUnNorm, \"Data/AllTeamsFullLTGraphStandardized.edgelist\", delimiter=\",,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandardizeGraphs()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeTrainValTest():\n",
    "    \n",
    "    STtrainset = []\n",
    "    STtestset = []\n",
    "    STvalset = []\n",
    "    \n",
    "    STGraphFullNorm = nx.read_weighted_edgelist(\"Data/AllTeamsFullSTGraphStandardized.edgelist\", delimiter=\",,\")\n",
    "    LTGraphFullNorm = nx.read_weighted_edgelist(\"Data/AllTeamsFullLTGraphStandardized.edgelist\", delimiter=\",,\")\n",
    "\n",
    "    print(len(LTGraphFullNorm.edges()))\n",
    "    #25126 total, so 20100 train, 2513 val, 2513 test\n",
    "    \n",
    "    #FIX THIS\n",
    "    \n",
    "    testlistLT = random.sample(LTGraphFullNorm.edges(),2513)\n",
    "    trainvalLT = [x for x in LTGraphFullNorm.edges() if x not in testlistLT]\n",
    "    vallistLT = random.sample(trainvalLT,2513)\n",
    "    trainlistLT = [x for x in trainvalLT if x not in vallistLT]\n",
    "    print(len(trainlistLT),len(vallistLT),len(testlistLT))\n",
    "    \n",
    "    for node1, node2, data in vallistLT:\n",
    "        print(data['weight'])\n",
    "            \n",
    "    traingraphLT = nx.from_edgelist(trainlistLT)\n",
    "    valgraphLT = nx.from_edgelist(vallistLT)\n",
    "    testgraphLT = nx.from_edgelist(testlistLT)    \n",
    "    nx.write_weighted_edgelist(traingraphLT, \"Data/AllTeamsFullLTGraphStandardizedTrain.edgelist\", delimiter=\",,\")\n",
    "    nx.write_weighted_edgelist(valgraphLT, \"Data/AllTeamsFullLTGraphStandardizedVal.edgelist\", delimiter=\",,\")\n",
    "    nx.write_weighted_edgelist(testgraphLT, \"Data/AllTeamsFullLTGraphStandardizedTest.edgelist\", delimiter=\",,\")\n",
    "    \n",
    "    testlistST = random.sample(STGraphFullNorm.edges(),2513)\n",
    "    trainvalST = [x for x in STGraphFullNorm.edges() if x not in testlistST]\n",
    "    vallistST = random.sample(trainvalST,2513)\n",
    "    trainlistST = [x for x in trainvalST if x not in vallistST]\n",
    "    print(len(trainlistST),len(vallistST),len(testlistST))\n",
    "    traingraphST = nx.from_edgelist(trainlistST)\n",
    "    valgraphST = nx.from_edgelist(vallistST)\n",
    "    testgraphST = nx.from_edgelist(testlistST)    \n",
    "    nx.write_weighted_edgelist(traingraphST, \"Data/AllTeamsFullSTGraphStandardizedTrain.edgelist\", delimiter=\",,\")\n",
    "    nx.write_weighted_edgelist(valgraphST, \"Data/AllTeamsFullSTGraphStandardizedVal.edgelist\", delimiter=\",,\")\n",
    "    nx.write_weighted_edgelist(testgraphST, \"Data/AllTeamsFullSTGraphStandardizedTest.edgelist\", delimiter=\",,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25126\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Population must be a sequence or set.  For dicts, use list(d).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-4d6fd095f4e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMakeTrainValTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-133208086856>\u001b[0m in \u001b[0;36mMakeTrainValTest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#25126 total, so 20100 train, 2513 val, 2513 test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtestlistLT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLTGraphFullNorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2513\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtrainvalLT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mLTGraphFullNorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestlistLT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvallistLT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainvalLT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2513\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Population must be a sequence or set.  For dicts, use list(d).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mrandbelow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Population must be a sequence or set.  For dicts, use list(d)."
     ]
    }
   ],
   "source": [
    "MakeTrainValTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
