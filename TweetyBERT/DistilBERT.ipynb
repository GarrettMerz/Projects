{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use DistilBERT to do the Twitter sentiment analysis task: https://www.kaggle.com/kazanova/sentiment140. The task is to classify tweets as positive (4) or negative (0). I'll relabel to 1 and 0.\n",
    "\n",
    "Some of this is adapted from the tutorial here: https://swatimeena989.medium.com/bert-text-classification-using-keras-903671e0207d, but on a new dataset (and with some additions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import string\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "from transformers import TFDistilBertModel, DistilBertConfig, DistilBertTokenizerFast, TFDistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import tensorflow.keras \n",
    "from tensorflow.keras.models import Sequential, Model \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cols = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "dataset = pd.read_csv('/home/garrett/KagglesData/training.1600000.processed.noemoticon.csv', header=None, encoding='ISO-8859-1', names=dataset_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all text in lowercase, remove Twitter handles, punctuation, websites, text in brackets or html tags, and words containing numbers. This does remove words like '2nite', but identifying and parsing 'textspeak' is a challenge that's a little beyond the scope of what I'm trying to investigate here (which is mainly just learning to correctly implement a form of BERT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.apply(lambda x: x.lower())\n",
    "    text = text.apply(lambda x: re.sub(r'@\\w+', '', x))\n",
    "    text = text.apply(lambda x:re.sub('\\[.*?\\]', '', x))\n",
    "    text = text.apply(lambda x:re.sub('https?://\\S+|www\\.\\S+', '', x))\n",
    "    text = text.apply(lambda x:re.sub('<.*?>+', '', x))\n",
    "    text = text.apply(lambda x:re.sub('[%s]' % re.escape(string.punctuation), ' ', x))\n",
    "    text = text.apply(lambda x:re.sub('\\n', '', x))\n",
    "    text = text.apply(lambda x:re.sub('\\w*\\d\\w*', '', x))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(dataset,random_state=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ~df.columns.str.contains('ids', case=False)] \n",
    "df = df.loc[:, ~df.columns.str.contains('date', case=False)] \n",
    "df = df.loc[:, ~df.columns.str.contains('flag', case=False)]\n",
    "df = df.loc[:, ~df.columns.str.contains('user', case=False)]\n",
    "print(df['text'][671155])\n",
    "df['text']=preprocess(df['text'])\n",
    "print(df['text'][671155])\n",
    "#df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the target onto a ground-truth of 0  or 1, check to make sure every tweet is labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gt'] = df['target'].map({0:0,4:1})\n",
    "sentences=df['text']\n",
    "labels=df['gt']\n",
    "len(sentences),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()                 \n",
    "df=df.reset_index(drop=True)\n",
    "print('Available labels: ',df['gt'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "bert_model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=[]\n",
    "attention_masks=[]\n",
    "\n",
    "for sent in sentences:\n",
    "    bert_inp=bert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =64,pad_to_max_length = True,return_attention_mask = True)\n",
    "    input_ids.append(bert_inp['input_ids'])\n",
    "    attention_masks.append(bert_inp['attention_mask'])\n",
    "\n",
    "input_ids=np.asarray(input_ids)\n",
    "attention_masks=np.array(attention_masks)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_ids),len(attention_masks),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Preparing the pickle file.....')\n",
    "\n",
    "pickle_inp_path='./bert_inp.pkl'\n",
    "pickle_mask_path='./bert_mask.pkl'\n",
    "pickle_label_path='./bert_label.pkl'\n",
    "\n",
    "pickle.dump((input_ids),open(pickle_inp_path,'wb'))\n",
    "pickle.dump((attention_masks),open(pickle_mask_path,'wb'))\n",
    "pickle.dump((labels),open(pickle_label_path,'wb'))\n",
    "\n",
    "\n",
    "print('Pickle files saved as ',pickle_inp_path,pickle_mask_path,pickle_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the saved pickle files..')\n",
    "\n",
    "input_ids=pickle.load(open(pickle_inp_path, 'rb'))\n",
    "attention_masks=pickle.load(open(pickle_mask_path, 'rb'))\n",
    "labels=pickle.load(open(pickle_label_path, 'rb'))\n",
    "\n",
    "print('Input shape {} Attention mask shape {} Input label shape {}'.format(input_ids.shape,attention_masks.shape,labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_inp,test_inp,trainval_label,test_label,trainval_mask,test_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.1)\n",
    "train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(trainval_inp,trainval_label,trainval_mask,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir='tensorboard_data/tb_bert'\n",
    "model_save_path='./models/bert_model.h5'\n",
    "\n",
    "callbacks = [tensorflow.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "\n",
    "loss = tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tensorflow.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tensorflow.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-08)\n",
    "\n",
    "bert_model.compile(loss=loss,optimizer=optimizer,metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nBert Model',bert_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=bert_model.fit([train_inp,train_mask],train_label,batch_size=128,epochs=4,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "log_dir='tensorboard_data/bert_model'\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
